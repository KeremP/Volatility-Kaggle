{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "necessary-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "path_root = './'\n",
    "path_data = './'\n",
    "path_submissions = '/'\n",
    "\n",
    "target_name = 'target'\n",
    "scores_folds = {}\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "geographic-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff() \n",
    "\n",
    "def realized_volatility(series_log_return):\n",
    "    return np.sqrt(np.sum(series_log_return**2))\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "\n",
    "\n",
    "def get_stock_stat(stock_id : int, dataType = 'train'):\n",
    "    key = ['stock_id', 'time_id', 'seconds_in_bucket']\n",
    "    \n",
    "    #Book features\n",
    "    df_book = pd.read_parquet(os.path.join(path_data, 'book_{}.parquet/stock_id={}/'.format(dataType, stock_id)))\n",
    "    df_book['stock_id'] = stock_id\n",
    "    cols = key + [col for col in df_book.columns if col not in key]\n",
    "    df_book = df_book[cols]\n",
    "    \n",
    "    df_book['wap1'] = (df_book['bid_price1'] * df_book['ask_size1'] +\n",
    "                                    df_book['ask_price1'] * df_book['bid_size1']) / (df_book['bid_size1'] + df_book['ask_size1'])\n",
    "    df_book['wap2'] = (df_book['bid_price2'] * df_book['ask_size2'] +\n",
    "                                    df_book['ask_price2'] * df_book['bid_size2']) / (df_book['bid_size2'] + df_book['ask_size2'])\n",
    "    df_book['log_return1'] = df_book.groupby(by = ['time_id'])['wap1'].apply(log_return).fillna(0)\n",
    "    df_book['log_return2'] = df_book.groupby(by = ['time_id'])['wap2'].apply(log_return).fillna(0)\n",
    "    \n",
    "    features_to_apply_realized_volatility = ['log_return'+str(i+1) for i in range(2)]\n",
    "    stock_stat = df_book.groupby(by = ['stock_id', 'time_id'])[features_to_apply_realized_volatility]\\\n",
    "                        .agg(realized_volatility).reset_index()\n",
    "\n",
    "    #Trade features\n",
    "    trade_stat =  pd.read_parquet(os.path.join(path_data,'trade_{}.parquet/stock_id={}'.format(dataType, stock_id)))\n",
    "    trade_stat = trade_stat.sort_values(by=['time_id', 'seconds_in_bucket']).reset_index(drop=True)\n",
    "    trade_stat['stock_id'] = stock_id\n",
    "    cols = key + [col for col in trade_stat.columns if col not in key]\n",
    "    trade_stat = trade_stat[cols]\n",
    "    trade_stat['trade_log_return1'] = trade_stat.groupby(by = ['time_id'])['price'].apply(log_return).fillna(0)\n",
    "    trade_stat = trade_stat.groupby(by = ['stock_id', 'time_id'])[['trade_log_return1']]\\\n",
    "                           .agg(realized_volatility).reset_index()\n",
    "    #Joining book and trade features\n",
    "    stock_stat = stock_stat.merge(trade_stat, on=['stock_id', 'time_id'], how='left').fillna(-999)\n",
    "    \n",
    "    return stock_stat\n",
    "\n",
    "def get_dataSet(stock_ids : list, dataType = 'train'):\n",
    "    \n",
    "    if DEBUG and dataType == 'train':\n",
    "        stock_ids = stock_ids[:10]\n",
    "\n",
    "    stock_stat = Parallel(n_jobs=-1)(\n",
    "        delayed(get_stock_stat)(stock_id, dataType) \n",
    "        for stock_id in stock_ids\n",
    "    )\n",
    "    \n",
    "    stock_stat_df = pd.concat(stock_stat, ignore_index = True)\n",
    "\n",
    "    return stock_stat_df\n",
    "\n",
    "def feval_RMSPE(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'RMSPE', round(rmspe(y_true = labels, y_pred = preds),5), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "adverse-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(path_data,'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "prepared-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(os.path.join(path_data, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "occasional-attraction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 7s\n",
      "Train shape: (428932, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "      <th>log_return1</th>\n",
       "      <th>log_return2</th>\n",
       "      <th>trade_log_return1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.002006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  time_id    target  log_return1  log_return2  trade_log_return1\n",
       "0         0        5  0.004136     0.004499     0.006999           0.002006\n",
       "1         0       11  0.001445     0.001204     0.002476           0.000901"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (3, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>log_return1</th>\n",
       "      <th>log_return2</th>\n",
       "      <th>trade_log_return1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0-32</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0-34</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  time_id row_id  log_return1  log_return2  trade_log_return1\n",
       "0         0        4    0-4     0.000294     0.000252           0.000295\n",
       "1         0       32   0-32     0.000000     0.000000           0.000000\n",
       "2         0       34   0-34     0.000000     0.000000           0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(path_data, 'train.csv'))\n",
    "%time train_stock_stat_df = get_dataSet(stock_ids = train['stock_id'].unique(), dataType = 'train')\n",
    "train = pd.merge(train, train_stock_stat_df, on = ['stock_id', 'time_id'], how = 'left').fillna(0)\n",
    "print('Train shape: {}'.format(train.shape))\n",
    "display(train.head(2))\n",
    "\n",
    "test = pd.read_csv(os.path.join(path_data, 'test.csv'))\n",
    "test_stock_stat_df = get_dataSet(stock_ids = test['stock_id'].unique(), dataType = 'test')\n",
    "test = pd.merge(test, test_stock_stat_df, on = ['stock_id', 'time_id'], how = 'left').fillna(0)\n",
    "print('Test shape: {}'.format(test.shape))\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "indie-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "inner-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "limited-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define dataset/dataloader\n",
    "\n",
    "class VolatilityDataset(Dataset):\n",
    "    def __init__(self, X,y, emb_cols=['stock_id','time_id']):\n",
    "        X = X.copy()\n",
    "        self.X1 = X.loc[:,emb_cols].copy().values.astype(np.int8)\n",
    "        self.X2 = X.drop(columns=emb_cols).copy().values.astype(np.float32)\n",
    "        \n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.tensor(np.expand_dims(self.X1[idx], 0)).int().to(device), torch.FloatTensor(np.expand_dims(self.X2[idx],0)).to(device)), torch.FloatTensor(np.expand_dims(self.y[idx],0)).to(device)\n",
    "    \n",
    "class VolatilityDatasetTest(Dataset):\n",
    "    def __init__(self, X, emb_cols=['stock_id','time_id']):\n",
    "        X = X.copy()\n",
    "        \n",
    "        self.X1 = X.loc[:,emb_cols].copy().values.astype(np.int8)\n",
    "        self.X2 = X.drop(columns=emb_cols).copy().values.astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X1)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.tensor(np.expand_dims(self.X1[idx],0)).int().to(device),torch.FloatTensor(np.expand_dims(self.X2[idx],0)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "advisory-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['stock_id'] = train['stock_id'].astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "advance-drinking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428932, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "      <th>log_return1</th>\n",
       "      <th>log_return2</th>\n",
       "      <th>trade_log_return1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.002006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.001961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.001561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.000871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  time_id    target  log_return1  log_return2  trade_log_return1\n",
       "0         0        5  0.004136     0.004499     0.006999           0.002006\n",
       "1         0       11  0.001445     0.001204     0.002476           0.000901\n",
       "2         0       16  0.002168     0.002369     0.004801           0.001961\n",
       "3         0       31  0.002195     0.002574     0.003637           0.001561\n",
       "4         0       62  0.001747     0.001894     0.003257           0.000871"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "display(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "interim-norway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[116]],\n",
      "\n",
      "        [[ 41]],\n",
      "\n",
      "        [[ 74]],\n",
      "\n",
      "        [[124]]], device='cuda:0', dtype=torch.int32), tensor([[[0.0036, 0.0056, 0.0026]],\n",
      "\n",
      "        [[0.0010, 0.0011, 0.0007]],\n",
      "\n",
      "        [[0.0008, 0.0013, 0.0009]],\n",
      "\n",
      "        [[0.0020, 0.0026, 0.0017]]], device='cuda:0')) tensor([[0.0056],\n",
      "        [0.0014],\n",
      "        [0.0012],\n",
      "        [0.0025]], device='cuda:0')\n",
      "(torch.Size([4, 1, 1]), torch.Size([4, 1, 3])) torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = VolatilityDataset(train.drop(['target','time_id'], axis=1), train['target'], emb_cols=['stock_id'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "for (emb, cont), target in train_loader:\n",
    "#     emb, cont, target = emb.unsqueeze(0), cont.unsqueeze(0), target.unsqueeze(0)\n",
    "    print((emb, cont), target)\n",
    "    print((emb.shape, cont.shape), target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "smoking-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_features, embedding_size=16, num_embeddings=max(train['stock_id']) +1):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(num_embeddings, embedding_size)\n",
    "        self.emb_drop = nn.Dropout(0.25)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(1)\n",
    "        \n",
    "        self.n_features = n_features\n",
    "        \n",
    "        self.embedding_size, self.hidden_dim = embedding_size, 2*embedding_size\n",
    "        \n",
    "        self.rnn1 = nn.LSTM(\n",
    "            input_size = n_features,\n",
    "            hidden_size = self.hidden_dim,\n",
    "            num_layers = 1,\n",
    "            batch_first = True\n",
    "        )\n",
    "        \n",
    "        self.rnn2 = nn.LSTM(\n",
    "            input_size = self.hidden_dim,\n",
    "            hidden_size = embedding_size,\n",
    "            num_layers = 1,\n",
    "            batch_first = True\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x1 = self.emb(x_cat)\n",
    "        x1 = torch.flatten(x1, end_dim=1)\n",
    "        x1 = self.emb_drop(x1)\n",
    "        \n",
    "        x2 = self.bn1(x_cont)\n",
    "        x = torch.cat([x1,x2],1)\n",
    "        x, (_,_) = self.rnn1(x)\n",
    "        x = F.relu(x)\n",
    "        x, (hidden,_) = self.rnn2(x)\n",
    "        \n",
    "        return hidden\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "transsexual-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, seq_len, input_dim=16, n_features=10):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim, self.n_features = 2*input_dim, n_features\n",
    "        \n",
    "        self.rnn1 = nn.LSTM(\n",
    "            input_size = input_dim,\n",
    "            hidden_size = input_dim,\n",
    "            num_layers = 1,\n",
    "            batch_first = True\n",
    "        )\n",
    "        \n",
    "        self.rnn2 = nn.LSTM(\n",
    "            input_size = input_dim,\n",
    "            hidden_size = self.hidden_dim,\n",
    "            num_layers = 1,\n",
    "            batch_first = True\n",
    "        )\n",
    "        \n",
    "        self.output_layer = nn.Linear(self.hidden_dim, n_features)\n",
    "        \n",
    "    def forward(self, x, _):\n",
    "        x, (hidden, cell) = self.rnn1(x)\n",
    "        x, (hidden, cell) = self.rnn2(x)\n",
    "        \n",
    "        return self.output_layer(x)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "effective-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "western-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAE(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_features, embedding_dim=3):\n",
    "        super(RAE, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(n_features, embedding_dim).to(device)\n",
    "        \n",
    "        self.decoder = Decoder(embedding_dim, n_features).to(device)\n",
    "        \n",
    "    def forward(self, cats, conts):\n",
    "        x = self.encoder(cats, conts)\n",
    "        x = self.decoder(x,conts)\n",
    "        \n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "possible-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSELoss(yhat,y):\n",
    "    return torch.sqrt(torch.mean((yhat-y)**2))\n",
    "\n",
    "def RMSPELoss(y_pred, y_true):\n",
    "    return torch.sqrt(torch.mean( ((y_true - y_pred) / y_true) ** 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "reflected-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(train, valid, test=None, batch_size=64, drop_cols=['target', 'time_id'], emb_cols=['stock_id']):\n",
    "    train_dataset = VolatilityDataset(train.drop(drop_cols, axis=1), train['target'], emb_cols=emb_cols)\n",
    "    valid_dataset = VolatilityDataset(valid.drop(drop_cols, axis=1), valid['target'], emb_cols=emb_cols)    \n",
    "    \n",
    "    train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_dl = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return train_dl, valid_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "weird-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = model_selection.KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "seed_everything(46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "proud-riverside",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_dl, valid_dl, model, loss_fn, opt, sch, epoch, fold, device=device):\n",
    "    # taining loop\n",
    "    model.train()\n",
    "    running_loss_ = 0\n",
    "    \n",
    "    pbar = tqdm(enumerate(train_dl), total=len(train_dl))\n",
    "    for i, ((cats, counts), targets) in pbar:\n",
    "        cats, counts, targets = cats.to(device), counts.to(device), targets.unsqueeze(1).to(device)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        y_pred = model(cats, counts)\n",
    "        loss = loss_fn(y_pred.float(), targets.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        running_loss_ += loss.item()\n",
    "        if (i+1) % 100 == 0:\n",
    "            pbar.set_description(f\"running loss:{running_loss_ / (i+1): 0.6f}\")\n",
    "    \n",
    "    sch.step(loss)\n",
    "\n",
    "    epoch_loss = running_loss_ / len(train_dl)\n",
    "    #print(f'==> Epoch {epoch} TRAIN loss: {epoch_loss:.6f}')\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for i, ((cats, counts), targets) in enumerate(valid_dl):\n",
    "        cats, counts, targets = cats.to(device), counts.to(device), targets.unsqueeze(1).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred = model(cats, counts)\n",
    "            val_loss = loss_fn(y_pred.float(), targets.float())\n",
    "            \n",
    "        valid_loss += val_loss.item() * targets.shape[0]\n",
    "    sch.step(valid_loss)\n",
    "    \n",
    "    valid_epoch_loss = valid_loss / len(valid_dl)\n",
    "    print(f'==>F{fold}, Epoch {epoch} VALID loss: {valid_epoch_loss:.8f}')\n",
    "    \n",
    "    if valid_epoch_loss < best_loss:\n",
    "        best_loss = valid_epoch_loss\n",
    "        torch.save(model.state_dict(), f'FOLD{fold}_optive_model.pth')\n",
    "    \n",
    "    model.train()\n",
    "    return model, epoch_loss, valid_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "finite-complaint",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 3/5027 [00:00<03:00, 27.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.005360: 100%|██████████████████████████████████████████████████████| 5027/5027 [01:48<00:00, 46.47it/s]\n",
      "  0%|                                                                                 | 4/5027 [00:00<02:09, 38.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F0, Epoch 0 VALID loss: 0.19185096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002932: 100%|██████████████████████████████████████████████████████| 5027/5027 [01:47<00:00, 46.92it/s]\n",
      "  0%|                                                                                 | 4/5027 [00:00<02:05, 40.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F0, Epoch 1 VALID loss: 0.18530140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002880: 100%|██████████████████████████████████████████████████████| 5027/5027 [01:46<00:00, 47.32it/s]\n",
      "  0%|                                                                                 | 5/5027 [00:00<02:00, 41.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F0, Epoch 2 VALID loss: 0.18440681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002868: 100%|██████████████████████████████████████████████████████| 5027/5027 [01:46<00:00, 47.02it/s]\n",
      "  0%|                                                                                 | 5/5027 [00:00<01:59, 42.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F0, Epoch 3 VALID loss: 0.18499740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002864: 100%|██████████████████████████████████████████████████████| 5027/5027 [01:46<00:00, 47.15it/s]\n",
      "  0%|                                                                                 | 5/5027 [00:00<01:57, 42.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F0, Epoch 4 VALID loss: 0.18447060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002865: 100%|██████████████████████████████████████████████████████| 5027/5027 [03:03<00:00, 27.45it/s]\n",
      "  0%|                                                                                 | 2/5027 [00:00<04:56, 16.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F0, Epoch 5 VALID loss: 0.18481373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002860: 100%|██████████████████████████████████████████████████████| 5027/5027 [05:31<00:00, 15.17it/s]\n",
      "  0%|                                                                                 | 2/5027 [00:00<04:26, 18.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F0, Epoch 6 VALID loss: 0.18389852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002861: 100%|██████████████████████████████████████████████████████| 5027/5027 [05:09<00:00, 16.24it/s]\n",
      "  0%|                                                                                 | 2/5027 [00:00<05:04, 16.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F0, Epoch 7 VALID loss: 0.18351187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002854: 100%|██████████████████████████████████████████████████████| 5027/5027 [05:13<00:00, 16.03it/s]\n",
      "  0%|                                                                                         | 0/5027 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F0, Epoch 8 VALID loss: 0.18379878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002859: 100%|██████████████████████████████████████████████████████| 5027/5027 [05:03<00:00, 16.54it/s]\n",
      "  0%|                                                                                         | 0/5027 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F0, Epoch 9 VALID loss: 0.18363176\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.006211: 100%|██████████████████████████████████████████████████████| 5027/5027 [04:41<00:00, 17.87it/s]\n",
      "  0%|                                                                                         | 0/5027 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F1, Epoch 0 VALID loss: 0.19185244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002950: 100%|██████████████████████████████████████████████████████| 5027/5027 [05:05<00:00, 16.48it/s]\n",
      "  0%|                                                                                 | 2/5027 [00:00<04:36, 18.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F1, Epoch 1 VALID loss: 0.18364388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002888: 100%|██████████████████████████████████████████████████████| 5027/5027 [05:13<00:00, 16.02it/s]\n",
      "  0%|                                                                                 | 2/5027 [00:00<04:36, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F1, Epoch 2 VALID loss: 0.18407600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002876: 100%|██████████████████████████████████████████████████████| 5027/5027 [05:24<00:00, 15.51it/s]\n",
      "  0%|                                                                                 | 2/5027 [00:00<05:03, 16.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F1, Epoch 3 VALID loss: 0.18607635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002870: 100%|██████████████████████████████████████████████████████| 5027/5027 [05:00<00:00, 16.76it/s]\n",
      "  0%|                                                                                 | 3/5027 [00:00<02:50, 29.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F1, Epoch 4 VALID loss: 0.18195467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002868: 100%|██████████████████████████████████████████████████████| 5027/5027 [01:50<00:00, 45.45it/s]\n",
      "  0%|                                                                                 | 5/5027 [00:00<01:59, 42.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F1, Epoch 5 VALID loss: 0.18217214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002871: 100%|██████████████████████████████████████████████████████| 5027/5027 [01:45<00:00, 47.53it/s]\n",
      "  0%|                                                                                 | 5/5027 [00:00<01:51, 45.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F1, Epoch 6 VALID loss: 0.18202463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002870: 100%|██████████████████████████████████████████████████████| 5027/5027 [01:44<00:00, 48.11it/s]\n",
      "  0%|                                                                                 | 5/5027 [00:00<01:58, 42.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F1, Epoch 7 VALID loss: 0.18199306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002869: 100%|██████████████████████████████████████████████████████| 5027/5027 [01:43<00:00, 48.57it/s]\n",
      "  0%|                                                                                 | 5/5027 [00:00<02:03, 40.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F1, Epoch 8 VALID loss: 0.18192434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002869: 100%|██████████████████████████████████████████████████████| 5027/5027 [01:43<00:00, 48.41it/s]\n",
      "  0%|                                                                                 | 5/5027 [00:00<01:53, 44.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F1, Epoch 9 VALID loss: 0.18195948\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.005149: 100%|██████████████████████████████████████████████████████| 5027/5027 [01:43<00:00, 48.69it/s]\n",
      "  0%|                                                                                 | 4/5027 [00:00<02:10, 38.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F2, Epoch 0 VALID loss: 0.19195243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002928: 100%|██████████████████████████████████████████████████████| 5027/5027 [05:20<00:00, 15.68it/s]\n",
      "  0%|                                                                                 | 2/5027 [00:00<06:06, 13.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F2, Epoch 1 VALID loss: 0.18535199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002876: 100%|██████████████████████████████████████████████████████| 5027/5027 [05:17<00:00, 15.82it/s]\n",
      "  0%|                                                                                 | 2/5027 [00:00<04:28, 18.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F2, Epoch 2 VALID loss: 0.18481731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002868: 100%|██████████████████████████████████████████████████████| 5027/5027 [04:39<00:00, 18.00it/s]\n",
      "  0%|                                                                                 | 2/5027 [00:00<04:31, 18.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F2, Epoch 3 VALID loss: 0.18453397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002859: 100%|██████████████████████████████████████████████████████| 5027/5027 [03:59<00:00, 20.99it/s]\n",
      "  0%|                                                                                 | 2/5027 [00:00<04:26, 18.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F2, Epoch 4 VALID loss: 0.18417449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002859: 100%|██████████████████████████████████████████████████████| 5027/5027 [03:36<00:00, 23.21it/s]\n",
      "  0%|                                                                                 | 3/5027 [00:00<03:42, 22.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F2, Epoch 5 VALID loss: 0.18405335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002859: 100%|██████████████████████████████████████████████████████| 5027/5027 [03:21<00:00, 24.96it/s]\n",
      "  0%|                                                                                 | 2/5027 [00:00<04:21, 19.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F2, Epoch 6 VALID loss: 0.18433653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002859: 100%|██████████████████████████████████████████████████████| 5027/5027 [03:23<00:00, 24.69it/s]\n",
      "  0%|                                                                                 | 2/5027 [00:00<04:26, 18.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F2, Epoch 7 VALID loss: 0.18447923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002855: 100%|██████████████████████████████████████████████████████| 5027/5027 [03:17<00:00, 25.41it/s]\n",
      "  0%|                                                                                 | 2/5027 [00:00<05:49, 14.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F2, Epoch 8 VALID loss: 0.18413810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002859: 100%|██████████████████████████████████████████████████████| 5027/5027 [03:12<00:00, 26.08it/s]\n",
      "  0%|                                                                                         | 0/5027 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F2, Epoch 9 VALID loss: 0.18395563\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.005663: 100%|██████████████████████████████████████████████████████| 5027/5027 [03:05<00:00, 27.15it/s]\n",
      "  0%|                                                                                 | 2/5027 [00:00<04:18, 19.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F3, Epoch 0 VALID loss: 0.19106658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002939: 100%|██████████████████████████████████████████████████████| 5027/5027 [03:05<00:00, 27.14it/s]\n",
      "  0%|                                                                                 | 2/5027 [00:00<04:26, 18.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F3, Epoch 1 VALID loss: 0.18434374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002881: 100%|██████████████████████████████████████████████████████| 5027/5027 [03:08<00:00, 26.72it/s]\n",
      "  0%|                                                                                 | 3/5027 [00:00<03:47, 22.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F3, Epoch 2 VALID loss: 0.18305389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002875: 100%|██████████████████████████████████████████████████████| 5027/5027 [03:02<00:00, 27.60it/s]\n",
      "  0%|                                                                                 | 2/5027 [00:00<04:56, 16.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F3, Epoch 3 VALID loss: 0.18263782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002871: 100%|██████████████████████████████████████████████████████| 5027/5027 [03:05<00:00, 27.03it/s]\n",
      "  0%|                                                                                 | 2/5027 [00:00<05:14, 16.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F3, Epoch 4 VALID loss: 0.18294447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002866: 100%|██████████████████████████████████████████████████████| 5027/5027 [03:02<00:00, 27.48it/s]\n",
      "  0%|                                                                                 | 2/5027 [00:00<04:26, 18.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F3, Epoch 5 VALID loss: 0.18278103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002866: 100%|██████████████████████████████████████████████████████| 5027/5027 [02:55<00:00, 28.62it/s]\n",
      "  0%|                                                                                 | 3/5027 [00:00<03:31, 23.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F3, Epoch 6 VALID loss: 0.18257517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002863: 100%|██████████████████████████████████████████████████████| 5027/5027 [02:58<00:00, 28.19it/s]\n",
      "  0%|                                                                                 | 2/5027 [00:00<04:23, 19.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F3, Epoch 7 VALID loss: 0.18260365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002866: 100%|██████████████████████████████████████████████████████| 5027/5027 [03:00<00:00, 27.88it/s]\n",
      "  0%|                                                                                 | 2/5027 [00:00<04:33, 18.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F3, Epoch 8 VALID loss: 0.18256183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.002863: 100%|██████████████████████████████████████████████████████| 5027/5027 [02:58<00:00, 28.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F3, Epoch 9 VALID loss: 0.18262851\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for _fold, (tr, te) in enumerate(kf.split(range(len(train)))):\n",
    "    print(_fold)\n",
    "    \n",
    "    trainSet = train.loc[tr].reset_index(drop=True)\n",
    "    valSet = train.loc[te].reset_index(drop=True)\n",
    "    \n",
    "    trainDl, valDl = prepare_dataset(trainSet, valSet)\n",
    "    \n",
    "    model = RAE(3).to(device)\n",
    "    \n",
    "    loss_fn = RMSELoss\n",
    "    \n",
    "    opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "    sch = optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.2, patience=3)\n",
    "    \n",
    "    counter = 0 \n",
    "    for epoch in range(epochs):\n",
    "        model, epoch_loss, valid_epoch_loss = train_epoch(trainDl, valDl, model, loss_fn, opt, sch, epoch, _fold, device=device)\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
