{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "continuing-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "path_root = './'\n",
    "data_dir ='./'\n",
    "path_submissions = '/'\n",
    "\n",
    "target_name = 'target'\n",
    "\n",
    "DEBUG = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suspected-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff() \n",
    "\n",
    "def realized_volatility(series_log_return):\n",
    "    return np.sqrt(np.sum(series_log_return**2))\n",
    "\n",
    "def realized_mad(series_log_return):\n",
    "    return np.mean(np.absolute(series_log_return - np.mean(series_log_return)))\n",
    "\n",
    "def realized_median_abs_dev(series_log_return):\n",
    "    return stats.median_absolute_deviation(series_log_return, nan_policy='omit')\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "\n",
    "def calc_wap(df):\n",
    "    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1'])/(df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "def calc_wap2(df):\n",
    "    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2'])/(df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "def count_unique(series):\n",
    "    return len(np.unique(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nominated-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor_book(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    \n",
    "    df['wap'] = calc_wap(df)\n",
    "    df['log_return'] = df.groupby('time_id')['wap'].apply(log_return)\n",
    "    \n",
    "    df['wap2'] = calc_wap(df)\n",
    "    df['log_return2'] = df.groupby('time_id')['wap2'].apply(log_return)\n",
    "    \n",
    "    df['wap_imbalance'] = abs(df['wap'] - df['wap2'])\n",
    "    \n",
    "    df['spread'] = (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1'])/2)\n",
    "    \n",
    "    df['bid_spread'] = df['bid_price1'] - df['bid_price2']\n",
    "    df['ask_spread'] = df['ask_price1'] - df['ask_price2']\n",
    "    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n",
    "    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n",
    "    \n",
    "    agg_dict = {\n",
    "        'log_return':[realized_volatility,realized_mad,realized_median_abs_dev],\n",
    "        'log_return2':[realized_volatility,realized_mad,realized_median_abs_dev],\n",
    "        'wap_imbalance':[np.mean],\n",
    "        'spread':[np.mean],\n",
    "        'bid_spread':[np.mean],\n",
    "        'ask_spread':[np.mean],\n",
    "        'volume_imbalance':[np.mean],\n",
    "        'total_volume':[np.mean],\n",
    "        'wap':[np.mean],\n",
    "    }\n",
    "    \n",
    "    \n",
    "    df_feature = pd.DataFrame(df.groupby(['time_id']).agg(agg_dict)).reset_index()\n",
    "    \n",
    "    df_feature.columns = ['_'.join(col) for col in df_feature.columns] #time_id is changed to time_id_\n",
    "        \n",
    "    #create row_id\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    df_feature = df_feature.drop(['time_id_'],axis=1)\n",
    "    \n",
    "    return df_feature\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "first-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor_trade(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['log_return'] = df.groupby('time_id')['price'].apply(log_return)\n",
    "    df['dollar_volume'] = df['price'] * df['size']\n",
    "    \n",
    "    \n",
    "    agg_dict = {\n",
    "        'log_return':[realized_volatility,realized_mad,realized_median_abs_dev],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum],\n",
    "        'order_count':[np.mean],\n",
    "        'dollar_volume':[np.sum],\n",
    "    }\n",
    "    \n",
    "    df_feature = df.groupby('time_id').agg(agg_dict).reset_index()\n",
    "    \n",
    "    df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "\n",
    "    \n",
    "    df_feature = df_feature.add_prefix('trade_')\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['trade_time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    df_feature = df_feature.drop(['trade_time_id_'],axis=1)\n",
    "    \n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "boring-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(list_stock_ids, is_train = True):\n",
    "    from joblib import Parallel, delayed # parallel computing to save time\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    def for_joblib(stock_id):\n",
    "        if is_train:\n",
    "            file_path_book = data_dir + \"book_train.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_train.parquet/stock_id=\" + str(stock_id)\n",
    "        else:\n",
    "            file_path_book = data_dir + \"book_test.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_test.parquet/stock_id=\" + str(stock_id)\n",
    "            \n",
    "        df_tmp = pd.merge(preprocessor_book(file_path_book),preprocessor_trade(file_path_trade),on='row_id',how='left')\n",
    "     \n",
    "        return pd.concat([df,df_tmp])\n",
    "    \n",
    "    df = Parallel(n_jobs=-1, verbose=1)(\n",
    "        delayed(for_joblib)(stock_id) for stock_id in list_stock_ids\n",
    "        )\n",
    "\n",
    "    df =  pd.concat(df,ignore_index = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "identified-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(data_dir,'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "remarkable-conversation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cusum_filter(raw_time_series, threshold, time_stamps=True):\n",
    "    \"\"\"\n",
    "    Advances in Financial Machine Learning, Snippet 2.4, page 39.\n",
    "\n",
    "    The Symmetric Dynamic/Fixed CUSUM Filter.\n",
    "\n",
    "    The CUSUM filter is a quality-control method, designed to detect a shift in the mean value of a measured quantity\n",
    "    away from a target value. The filter is set up to identify a sequence of upside or downside divergences from any\n",
    "    reset level zero. We sample a bar t if and only if S_t >= threshold, at which point S_t is reset to 0.\n",
    "\n",
    "    One practical aspect that makes CUSUM filters appealing is that multiple events are not triggered by raw_time_series\n",
    "    hovering around a threshold level, which is a flaw suffered by popular market signals such as Bollinger Bands.\n",
    "    It will require a full run of length threshold for raw_time_series to trigger an event.\n",
    "\n",
    "    Once we have obtained this subset of event-driven bars, we will let the ML algorithm determine whether the occurrence\n",
    "    of such events constitutes actionable intelligence. Below is an implementation of the Symmetric CUSUM filter.\n",
    "\n",
    "    Note: As per the book this filter is applied to closing prices but we extended it to also work on other\n",
    "    time series such as volatility.\n",
    "\n",
    "    :param raw_time_series: (pd.Series) Close prices (or other time series, e.g. volatility).\n",
    "    :param threshold: (float or pd.Series) When the abs(change) is larger than the threshold, the function captures\n",
    "                      it as an event, can be dynamic if threshold is pd.Series\n",
    "    :param time_stamps: (bool) Default is to return a DateTimeIndex, change to false to have it return a list.\n",
    "    :return: (datetime index vector) Vector of datetimes when the events occurred. This is used later to sample.\n",
    "    \"\"\"\n",
    "\n",
    "    t_events = []\n",
    "    s_pos = 0\n",
    "    s_neg = 0\n",
    "\n",
    "    # log returns\n",
    "    raw_time_series = pd.DataFrame(raw_time_series)  # Convert to DataFrame\n",
    "    raw_time_series.columns = ['price']\n",
    "    raw_time_series['log_ret'] = raw_time_series.price.apply(np.log).diff()\n",
    "    if isinstance(threshold, (float, int)):\n",
    "        raw_time_series['threshold'] = threshold\n",
    "    elif isinstance(threshold, pd.Series):\n",
    "        raw_time_series.loc[threshold.index, 'threshold'] = threshold\n",
    "    else:\n",
    "        raise ValueError('threshold is neither float nor pd.Series!')\n",
    "\n",
    "    raw_time_series = raw_time_series.iloc[1:]  # Drop first na values\n",
    "\n",
    "    # Get event time stamps for the entire series\n",
    "    for tup in raw_time_series.itertuples():\n",
    "        thresh = tup.threshold\n",
    "        pos = float(s_pos + tup.log_ret)\n",
    "        neg = float(s_neg + tup.log_ret)\n",
    "        s_pos = max(0.0, pos)\n",
    "        s_neg = min(0.0, neg)\n",
    "\n",
    "        if s_neg < -thresh:\n",
    "            s_neg = 0\n",
    "            t_events.append(tup.Index)\n",
    "\n",
    "        elif s_pos > thresh:\n",
    "            s_pos = 0\n",
    "            t_events.append(tup.Index)\n",
    "\n",
    "    # Return DatetimeIndex or list\n",
    "    if time_stamps:\n",
    "        event_timestamps = pd.DatetimeIndex(t_events)\n",
    "        return event_timestamps\n",
    "\n",
    "    return t_events\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "educational-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_train_ids = cusum_filter(train['target'],.1,False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "little-rescue",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.iloc[filtered_train_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "undefined-square",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape (428932, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 112 out of 112 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_return_realized_volatility</th>\n",
       "      <th>log_return_realized_mad</th>\n",
       "      <th>log_return_realized_median_abs_dev</th>\n",
       "      <th>log_return2_realized_volatility</th>\n",
       "      <th>log_return2_realized_mad</th>\n",
       "      <th>log_return2_realized_median_abs_dev</th>\n",
       "      <th>wap_imbalance_mean</th>\n",
       "      <th>spread_mean</th>\n",
       "      <th>bid_spread_mean</th>\n",
       "      <th>ask_spread_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>total_volume_mean</th>\n",
       "      <th>wap_mean</th>\n",
       "      <th>row_id</th>\n",
       "      <th>trade_log_return_realized_volatility</th>\n",
       "      <th>trade_log_return_realized_mad</th>\n",
       "      <th>trade_log_return_realized_median_abs_dev</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique</th>\n",
       "      <th>trade_size_sum</th>\n",
       "      <th>trade_order_count_mean</th>\n",
       "      <th>trade_dollar_volume_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>...</td>\n",
       "      <td>323.496689</td>\n",
       "      <td>1.003725</td>\n",
       "      <td>0-5</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>40</td>\n",
       "      <td>3179.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3190.139181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>...</td>\n",
       "      <td>411.450000</td>\n",
       "      <td>1.000239</td>\n",
       "      <td>0-11</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>30</td>\n",
       "      <td>1289.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1289.353432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>...</td>\n",
       "      <td>416.351064</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0-16</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>25</td>\n",
       "      <td>2161.0</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2158.608928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>...</td>\n",
       "      <td>435.266667</td>\n",
       "      <td>0.998832</td>\n",
       "      <td>0-31</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>15</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>1959.605547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>...</td>\n",
       "      <td>343.221591</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0-62</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>22</td>\n",
       "      <td>1791.0</td>\n",
       "      <td>4.045455</td>\n",
       "      <td>1790.254496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_return_realized_volatility  log_return_realized_mad  \\\n",
       "0                        0.004499                 0.000157   \n",
       "1                        0.001204                 0.000038   \n",
       "2                        0.002369                 0.000092   \n",
       "3                        0.002574                 0.000113   \n",
       "4                        0.001894                 0.000068   \n",
       "\n",
       "   log_return_realized_median_abs_dev  log_return2_realized_volatility  \\\n",
       "0                            0.000053                         0.004499   \n",
       "1                            0.000005                         0.001204   \n",
       "2                            0.000020                         0.002369   \n",
       "3                            0.000012                         0.002574   \n",
       "4                            0.000011                         0.001894   \n",
       "\n",
       "   log_return2_realized_mad  log_return2_realized_median_abs_dev  \\\n",
       "0                  0.000157                             0.000053   \n",
       "1                  0.000038                             0.000005   \n",
       "2                  0.000092                             0.000020   \n",
       "3                  0.000113                             0.000012   \n",
       "4                  0.000068                             0.000011   \n",
       "\n",
       "   wap_imbalance_mean  spread_mean  bid_spread_mean  ask_spread_mean  ...  \\\n",
       "0                 0.0     0.000852         0.000176        -0.000151  ...   \n",
       "1                 0.0     0.000394         0.000142        -0.000135  ...   \n",
       "2                 0.0     0.000725         0.000197        -0.000198  ...   \n",
       "3                 0.0     0.000860         0.000190        -0.000108  ...   \n",
       "4                 0.0     0.000397         0.000191        -0.000109  ...   \n",
       "\n",
       "   total_volume_mean  wap_mean  row_id trade_log_return_realized_volatility  \\\n",
       "0         323.496689  1.003725     0-5                             0.002006   \n",
       "1         411.450000  1.000239    0-11                             0.000901   \n",
       "2         416.351064  0.999542    0-16                             0.001961   \n",
       "3         435.266667  0.998832    0-31                             0.001561   \n",
       "4         343.221591  0.999619    0-62                             0.000871   \n",
       "\n",
       "   trade_log_return_realized_mad  trade_log_return_realized_median_abs_dev  \\\n",
       "0                       0.000271                                  0.000345   \n",
       "1                       0.000133                                  0.000149   \n",
       "2                       0.000298                                  0.000307   \n",
       "3                       0.000321                                  0.000383   \n",
       "4                       0.000138                                  0.000158   \n",
       "\n",
       "   trade_seconds_in_bucket_count_unique  trade_size_sum  \\\n",
       "0                                    40          3179.0   \n",
       "1                                    30          1289.0   \n",
       "2                                    25          2161.0   \n",
       "3                                    15          1962.0   \n",
       "4                                    22          1791.0   \n",
       "\n",
       "   trade_order_count_mean  trade_dollar_volume_sum  \n",
       "0                    2.75              3190.139181  \n",
       "1                     1.9              1289.353432  \n",
       "2                    2.72              2158.608928  \n",
       "3                3.933333              1959.605547  \n",
       "4                4.045455              1790.254496  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_return_realized_volatility</th>\n",
       "      <th>log_return_realized_mad</th>\n",
       "      <th>log_return_realized_median_abs_dev</th>\n",
       "      <th>log_return2_realized_volatility</th>\n",
       "      <th>log_return2_realized_mad</th>\n",
       "      <th>log_return2_realized_median_abs_dev</th>\n",
       "      <th>wap_imbalance_mean</th>\n",
       "      <th>spread_mean</th>\n",
       "      <th>bid_spread_mean</th>\n",
       "      <th>ask_spread_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>total_volume_mean</th>\n",
       "      <th>wap_mean</th>\n",
       "      <th>row_id</th>\n",
       "      <th>trade_log_return_realized_volatility</th>\n",
       "      <th>trade_log_return_realized_mad</th>\n",
       "      <th>trade_log_return_realized_median_abs_dev</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique</th>\n",
       "      <th>trade_size_sum</th>\n",
       "      <th>trade_order_count_mean</th>\n",
       "      <th>trade_dollar_volume_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>...</td>\n",
       "      <td>406.045161</td>\n",
       "      <td>0.999582</td>\n",
       "      <td>126-32751</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>37</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>2.783784</td>\n",
       "      <td>2568.838117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>0.004104</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>-0.000142</td>\n",
       "      <td>...</td>\n",
       "      <td>243.322870</td>\n",
       "      <td>1.002476</td>\n",
       "      <td>126-32753</td>\n",
       "      <td>0.002180</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>43</td>\n",
       "      <td>2323.0</td>\n",
       "      <td>3.418605</td>\n",
       "      <td>2327.828627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>0.003118</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>-0.000192</td>\n",
       "      <td>...</td>\n",
       "      <td>348.093750</td>\n",
       "      <td>1.001082</td>\n",
       "      <td>126-32758</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>35</td>\n",
       "      <td>3740.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3742.254714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>0.003661</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>-0.000134</td>\n",
       "      <td>...</td>\n",
       "      <td>426.416040</td>\n",
       "      <td>1.001809</td>\n",
       "      <td>126-32763</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>80</td>\n",
       "      <td>9389.0</td>\n",
       "      <td>2.925</td>\n",
       "      <td>9406.795437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>-0.000159</td>\n",
       "      <td>...</td>\n",
       "      <td>531.313364</td>\n",
       "      <td>1.000272</td>\n",
       "      <td>126-32767</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>36</td>\n",
       "      <td>5325.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5326.415054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        log_return_realized_volatility  log_return_realized_mad  \\\n",
       "428927                        0.003691                 0.000110   \n",
       "428928                        0.004104                 0.000170   \n",
       "428929                        0.003118                 0.000097   \n",
       "428930                        0.003661                 0.000110   \n",
       "428931                        0.002091                 0.000089   \n",
       "\n",
       "        log_return_realized_median_abs_dev  log_return2_realized_volatility  \\\n",
       "428927                            0.000029                         0.003691   \n",
       "428928                            0.000089                         0.004104   \n",
       "428929                            0.000016                         0.003118   \n",
       "428930                            0.000081                         0.003661   \n",
       "428931                            0.000057                         0.002091   \n",
       "\n",
       "        log_return2_realized_mad  log_return2_realized_median_abs_dev  \\\n",
       "428927                  0.000110                             0.000029   \n",
       "428928                  0.000170                             0.000089   \n",
       "428929                  0.000097                             0.000016   \n",
       "428930                  0.000110                             0.000081   \n",
       "428931                  0.000089                             0.000057   \n",
       "\n",
       "        wap_imbalance_mean  spread_mean  bid_spread_mean  ask_spread_mean  \\\n",
       "428927                 0.0     0.000878         0.000091        -0.000202   \n",
       "428928                 0.0     0.000706         0.000126        -0.000142   \n",
       "428929                 0.0     0.000739         0.000189        -0.000192   \n",
       "428930                 0.0     0.000530         0.000143        -0.000134   \n",
       "428931                 0.0     0.000432         0.000109        -0.000159   \n",
       "\n",
       "        ...  total_volume_mean  wap_mean     row_id  \\\n",
       "428927  ...         406.045161  0.999582  126-32751   \n",
       "428928  ...         243.322870  1.002476  126-32753   \n",
       "428929  ...         348.093750  1.001082  126-32758   \n",
       "428930  ...         426.416040  1.001809  126-32763   \n",
       "428931  ...         531.313364  1.000272  126-32767   \n",
       "\n",
       "       trade_log_return_realized_volatility  trade_log_return_realized_mad  \\\n",
       "428927                             0.002171                       0.000297   \n",
       "428928                             0.002180                       0.000225   \n",
       "428929                             0.001921                       0.000261   \n",
       "428930                             0.002051                       0.000182   \n",
       "428931                             0.001041                       0.000136   \n",
       "\n",
       "        trade_log_return_realized_median_abs_dev  \\\n",
       "428927                                  0.000409   \n",
       "428928                                  0.000213   \n",
       "428929                                  0.000332   \n",
       "428930                                  0.000224   \n",
       "428931                                  0.000130   \n",
       "\n",
       "        trade_seconds_in_bucket_count_unique  trade_size_sum  \\\n",
       "428927                                    37          2570.0   \n",
       "428928                                    43          2323.0   \n",
       "428929                                    35          3740.0   \n",
       "428930                                    80          9389.0   \n",
       "428931                                    36          5325.0   \n",
       "\n",
       "        trade_order_count_mean  trade_dollar_volume_sum  \n",
       "428927                2.783784              2568.838117  \n",
       "428928                3.418605              2327.828627  \n",
       "428929                     2.8              3742.254714  \n",
       "428930                   2.925              9406.795437  \n",
       "428931                     3.0              5326.415054  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_ids = train.stock_id.unique()\n",
    "\n",
    "df_train = preprocessor(list_stock_ids=train_ids, is_train=True)\n",
    "\n",
    "print(f'train shape {df_train.shape}')\n",
    "display(df_train.head())\n",
    "display(df_train.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "spanish-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.iloc[filtered_train_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "discrete-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n",
    "train = train[['row_id','target']]\n",
    "df_train = train.merge(df_train, on = ['row_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "perceived-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('train_processed.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
