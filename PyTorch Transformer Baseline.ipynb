{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "young-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "path_root = './'\n",
    "data_dir ='./'\n",
    "path_submissions = '/'\n",
    "\n",
    "target_name = 'target'\n",
    "\n",
    "DEBUG = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "secondary-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff() \n",
    "\n",
    "def realized_volatility(series_log_return):\n",
    "    return np.sqrt(np.sum(series_log_return**2))\n",
    "\n",
    "def realized_mad(series_log_return):\n",
    "    return np.mean(np.absolute(series_log_return - np.mean(series_log_return)))\n",
    "\n",
    "def realized_median_abs_dev(series_log_return):\n",
    "    return stats.median_absolute_deviation(series_log_return, nan_policy='omit')\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "\n",
    "def calc_wap(df):\n",
    "    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1'])/(df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n",
    "\n",
    "def calc_wap2(df):\n",
    "    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2'])/(df['bid_size2'] + df['ask_size2'])\n",
    "    return wap\n",
    "\n",
    "def count_unique(series):\n",
    "    return len(np.unique(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "crazy-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor_book(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    \n",
    "    df['wap'] = calc_wap(df)\n",
    "    df['log_return'] = df.groupby('time_id')['wap'].apply(log_return)\n",
    "    \n",
    "    df['wap2'] = calc_wap(df)\n",
    "    df['log_return2'] = df.groupby('time_id')['wap2'].apply(log_return)\n",
    "    \n",
    "    df['wap_imbalance'] = abs(df['wap'] - df['wap2'])\n",
    "    \n",
    "    df['spread'] = (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1'])/2)\n",
    "    \n",
    "    df['bid_spread'] = df['bid_price1'] - df['bid_price2']\n",
    "    df['ask_spread'] = df['ask_price1'] - df['ask_price2']\n",
    "    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n",
    "    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n",
    "    \n",
    "    agg_dict = {\n",
    "        'log_return':[realized_volatility,realized_mad,realized_median_abs_dev],\n",
    "        'log_return2':[realized_volatility,realized_mad,realized_median_abs_dev],\n",
    "        'wap_imbalance':[np.mean],\n",
    "        'spread':[np.mean],\n",
    "        'bid_spread':[np.mean],\n",
    "        'ask_spread':[np.mean],\n",
    "        'volume_imbalance':[np.mean],\n",
    "        'total_volume':[np.mean],\n",
    "        'wap':[np.mean],\n",
    "    }\n",
    "    \n",
    "    \n",
    "    df_feature = pd.DataFrame(df.groupby(['time_id']).agg(agg_dict)).reset_index()\n",
    "    \n",
    "    df_feature.columns = ['_'.join(col) for col in df_feature.columns] #time_id is changed to time_id_\n",
    "        \n",
    "    #create row_id\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    df_feature = df_feature.drop(['time_id_'],axis=1)\n",
    "    \n",
    "    return df_feature\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "broadband-banks",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.84 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_return_realized_volatility</th>\n",
       "      <th>log_return_realized_mad</th>\n",
       "      <th>log_return_realized_median_abs_dev</th>\n",
       "      <th>log_return2_realized_volatility</th>\n",
       "      <th>log_return2_realized_mad</th>\n",
       "      <th>log_return2_realized_median_abs_dev</th>\n",
       "      <th>wap_imbalance_mean</th>\n",
       "      <th>spread_mean</th>\n",
       "      <th>bid_spread_mean</th>\n",
       "      <th>ask_spread_mean</th>\n",
       "      <th>volume_imbalance_mean</th>\n",
       "      <th>total_volume_mean</th>\n",
       "      <th>wap_mean</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>134.894040</td>\n",
       "      <td>323.496689</td>\n",
       "      <td>1.003725</td>\n",
       "      <td>0-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>142.050000</td>\n",
       "      <td>411.450000</td>\n",
       "      <td>1.000239</td>\n",
       "      <td>0-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>141.414894</td>\n",
       "      <td>416.351064</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>146.216667</td>\n",
       "      <td>435.266667</td>\n",
       "      <td>0.998832</td>\n",
       "      <td>0-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>123.846591</td>\n",
       "      <td>343.221591</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0-62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3825</th>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>197.144781</td>\n",
       "      <td>374.235690</td>\n",
       "      <td>0.997938</td>\n",
       "      <td>0-32751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>233.781553</td>\n",
       "      <td>621.131068</td>\n",
       "      <td>1.000310</td>\n",
       "      <td>0-32753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>0.002913</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.002913</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>115.829787</td>\n",
       "      <td>343.734043</td>\n",
       "      <td>0.999552</td>\n",
       "      <td>0-32758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>132.074919</td>\n",
       "      <td>385.429967</td>\n",
       "      <td>1.002357</td>\n",
       "      <td>0-32763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>165.754386</td>\n",
       "      <td>533.543860</td>\n",
       "      <td>0.999123</td>\n",
       "      <td>0-32767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3830 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      log_return_realized_volatility  log_return_realized_mad  \\\n",
       "0                           0.004499                 0.000157   \n",
       "1                           0.001204                 0.000038   \n",
       "2                           0.002369                 0.000092   \n",
       "3                           0.002574                 0.000113   \n",
       "4                           0.001894                 0.000068   \n",
       "...                              ...                      ...   \n",
       "3825                        0.002579                 0.000078   \n",
       "3826                        0.002206                 0.000063   \n",
       "3827                        0.002913                 0.000134   \n",
       "3828                        0.003046                 0.000107   \n",
       "3829                        0.001901                 0.000074   \n",
       "\n",
       "      log_return_realized_median_abs_dev  log_return2_realized_volatility  \\\n",
       "0                               0.000053                         0.004499   \n",
       "1                               0.000005                         0.001204   \n",
       "2                               0.000020                         0.002369   \n",
       "3                               0.000012                         0.002574   \n",
       "4                               0.000011                         0.001894   \n",
       "...                                  ...                              ...   \n",
       "3825                            0.000016                         0.002579   \n",
       "3826                            0.000001                         0.002206   \n",
       "3827                            0.000075                         0.002913   \n",
       "3828                            0.000070                         0.003046   \n",
       "3829                            0.000054                         0.001901   \n",
       "\n",
       "      log_return2_realized_mad  log_return2_realized_median_abs_dev  \\\n",
       "0                     0.000157                             0.000053   \n",
       "1                     0.000038                             0.000005   \n",
       "2                     0.000092                             0.000020   \n",
       "3                     0.000113                             0.000012   \n",
       "4                     0.000068                             0.000011   \n",
       "...                        ...                                  ...   \n",
       "3825                  0.000078                             0.000016   \n",
       "3826                  0.000063                             0.000001   \n",
       "3827                  0.000134                             0.000075   \n",
       "3828                  0.000107                             0.000070   \n",
       "3829                  0.000074                             0.000054   \n",
       "\n",
       "      wap_imbalance_mean  spread_mean  bid_spread_mean  ask_spread_mean  \\\n",
       "0                    0.0     0.000852         0.000176        -0.000151   \n",
       "1                    0.0     0.000394         0.000142        -0.000135   \n",
       "2                    0.0     0.000725         0.000197        -0.000198   \n",
       "3                    0.0     0.000860         0.000190        -0.000108   \n",
       "4                    0.0     0.000397         0.000191        -0.000109   \n",
       "...                  ...          ...              ...              ...   \n",
       "3825                 0.0     0.000552         0.000083        -0.000182   \n",
       "3826                 0.0     0.000542         0.000092        -0.000172   \n",
       "3827                 0.0     0.000525         0.000202        -0.000083   \n",
       "3828                 0.0     0.000480         0.000113        -0.000166   \n",
       "3829                 0.0     0.000458         0.000124        -0.000127   \n",
       "\n",
       "      volume_imbalance_mean  total_volume_mean  wap_mean   row_id  \n",
       "0                134.894040         323.496689  1.003725      0-5  \n",
       "1                142.050000         411.450000  1.000239     0-11  \n",
       "2                141.414894         416.351064  0.999542     0-16  \n",
       "3                146.216667         435.266667  0.998832     0-31  \n",
       "4                123.846591         343.221591  0.999619     0-62  \n",
       "...                     ...                ...       ...      ...  \n",
       "3825             197.144781         374.235690  0.997938  0-32751  \n",
       "3826             233.781553         621.131068  1.000310  0-32753  \n",
       "3827             115.829787         343.734043  0.999552  0-32758  \n",
       "3828             132.074919         385.429967  1.002357  0-32763  \n",
       "3829             165.754386         533.543860  0.999123  0-32767  \n",
       "\n",
       "[3830 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "file_path = data_dir + \"book_train.parquet/stock_id=0\"\n",
    "preprocessor_book(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "isolated-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor_trade(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    df['log_return'] = df.groupby('time_id')['price'].apply(log_return)\n",
    "    df['dollar_volume'] = df['price'] * df['size']\n",
    "    \n",
    "    \n",
    "    agg_dict = {\n",
    "        'log_return':[realized_volatility,realized_mad,realized_median_abs_dev],\n",
    "        'seconds_in_bucket':[count_unique],\n",
    "        'size':[np.sum],\n",
    "        'order_count':[np.mean],\n",
    "        'dollar_volume':[np.sum],\n",
    "    }\n",
    "    \n",
    "    df_feature = df.groupby('time_id').agg(agg_dict).reset_index()\n",
    "    \n",
    "    df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n",
    "\n",
    "    \n",
    "    df_feature = df_feature.add_prefix('trade_')\n",
    "    stock_id = file_path.split('=')[1]\n",
    "    df_feature['row_id'] = df_feature['trade_time_id_'].apply(lambda x:f'{stock_id}-{x}')\n",
    "    df_feature = df_feature.drop(['trade_time_id_'],axis=1)\n",
    "    \n",
    "    return df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "waiting-horizontal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.81 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trade_log_return_realized_volatility</th>\n",
       "      <th>trade_log_return_realized_mad</th>\n",
       "      <th>trade_log_return_realized_median_abs_dev</th>\n",
       "      <th>trade_seconds_in_bucket_count_unique</th>\n",
       "      <th>trade_size_sum</th>\n",
       "      <th>trade_order_count_mean</th>\n",
       "      <th>trade_dollar_volume_sum</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>40</td>\n",
       "      <td>3179</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3190.139181</td>\n",
       "      <td>0-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>30</td>\n",
       "      <td>1289</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1289.353432</td>\n",
       "      <td>0-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>25</td>\n",
       "      <td>2161</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2158.608928</td>\n",
       "      <td>0-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001561</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>15</td>\n",
       "      <td>1962</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>1959.605547</td>\n",
       "      <td>0-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>22</td>\n",
       "      <td>1791</td>\n",
       "      <td>4.045455</td>\n",
       "      <td>1790.254496</td>\n",
       "      <td>0-62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3825</th>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>52</td>\n",
       "      <td>3450</td>\n",
       "      <td>3.057692</td>\n",
       "      <td>3441.815546</td>\n",
       "      <td>0-32751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>28</td>\n",
       "      <td>4547</td>\n",
       "      <td>3.892857</td>\n",
       "      <td>4548.671493</td>\n",
       "      <td>0-32753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>36</td>\n",
       "      <td>4250</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4247.563002</td>\n",
       "      <td>0-32758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>0.001794</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>53</td>\n",
       "      <td>3217</td>\n",
       "      <td>2.150943</td>\n",
       "      <td>3224.421796</td>\n",
       "      <td>0-32763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>29</td>\n",
       "      <td>3679</td>\n",
       "      <td>2.413793</td>\n",
       "      <td>3674.366695</td>\n",
       "      <td>0-32767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3830 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      trade_log_return_realized_volatility  trade_log_return_realized_mad  \\\n",
       "0                                 0.002006                       0.000271   \n",
       "1                                 0.000901                       0.000133   \n",
       "2                                 0.001961                       0.000298   \n",
       "3                                 0.001561                       0.000321   \n",
       "4                                 0.000871                       0.000138   \n",
       "...                                    ...                            ...   \n",
       "3825                              0.001519                       0.000162   \n",
       "3826                              0.001411                       0.000236   \n",
       "3827                              0.001521                       0.000206   \n",
       "3828                              0.001794                       0.000200   \n",
       "3829                              0.001197                       0.000181   \n",
       "\n",
       "      trade_log_return_realized_median_abs_dev  \\\n",
       "0                                     0.000345   \n",
       "1                                     0.000149   \n",
       "2                                     0.000307   \n",
       "3                                     0.000383   \n",
       "4                                     0.000158   \n",
       "...                                        ...   \n",
       "3825                                  0.000155   \n",
       "3826                                  0.000315   \n",
       "3827                                  0.000298   \n",
       "3828                                  0.000227   \n",
       "3829                                  0.000270   \n",
       "\n",
       "      trade_seconds_in_bucket_count_unique  trade_size_sum  \\\n",
       "0                                       40            3179   \n",
       "1                                       30            1289   \n",
       "2                                       25            2161   \n",
       "3                                       15            1962   \n",
       "4                                       22            1791   \n",
       "...                                    ...             ...   \n",
       "3825                                    52            3450   \n",
       "3826                                    28            4547   \n",
       "3827                                    36            4250   \n",
       "3828                                    53            3217   \n",
       "3829                                    29            3679   \n",
       "\n",
       "      trade_order_count_mean  trade_dollar_volume_sum   row_id  \n",
       "0                       2.75              3190.139181      0-5  \n",
       "1                        1.9              1289.353432     0-11  \n",
       "2                       2.72              2158.608928     0-16  \n",
       "3                   3.933333              1959.605547     0-31  \n",
       "4                   4.045455              1790.254496     0-62  \n",
       "...                      ...                      ...      ...  \n",
       "3825                3.057692              3441.815546  0-32751  \n",
       "3826                3.892857              4548.671493  0-32753  \n",
       "3827                     3.5              4247.563002  0-32758  \n",
       "3828                2.150943              3224.421796  0-32763  \n",
       "3829                2.413793              3674.366695  0-32767  \n",
       "\n",
       "[3830 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "file_path = data_dir + \"trade_train.parquet/stock_id=0\"\n",
    "preprocessor_trade(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "resident-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(list_stock_ids, is_train = True):\n",
    "    from joblib import Parallel, delayed # parallel computing to save time\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    def for_joblib(stock_id):\n",
    "        if is_train:\n",
    "            file_path_book = data_dir + \"book_train.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_train.parquet/stock_id=\" + str(stock_id)\n",
    "        else:\n",
    "            file_path_book = data_dir + \"book_test.parquet/stock_id=\" + str(stock_id)\n",
    "            file_path_trade = data_dir + \"trade_test.parquet/stock_id=\" + str(stock_id)\n",
    "            \n",
    "        df_tmp = pd.merge(preprocessor_book(file_path_book),preprocessor_trade(file_path_trade),on='row_id',how='left')\n",
    "     \n",
    "        return pd.concat([df,df_tmp])\n",
    "    \n",
    "    df = Parallel(n_jobs=-1, verbose=1)(\n",
    "        delayed(for_joblib)(stock_id) for stock_id in list_stock_ids\n",
    "        )\n",
    "\n",
    "    df =  pd.concat(df,ignore_index = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "terminal-testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(data_dir,'train.csv'))\n",
    "df_train = pd.read_csv('train_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "blind-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(os.path.join(data_dir,'test.csv'))\n",
    "test_ids = test.stock_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "heated-blast",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.05 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_test = preprocessor(list_stock_ids=test_ids, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "driving-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = test.merge(df_test, on=['row_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "waiting-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['stock_id'] = df_train['row_id'].apply(lambda x:x.split('-')[0])\n",
    "df_test['stock_id'] = df_test['row_id'].apply(lambda x:x.split('-')[0])\n",
    "df_train['time_id'] = df_train['row_id'].apply(lambda x:x.split('-')[1])\n",
    "df_test['time_id'] = df_test['row_id'].apply(lambda x:x.split('-')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "automated-protocol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row_id', 'target', 'log_return_realized_volatility',\n",
       "       'log_return_realized_mad', 'log_return_realized_median_abs_dev',\n",
       "       'log_return2_realized_volatility', 'log_return2_realized_mad',\n",
       "       'log_return2_realized_median_abs_dev', 'wap_imbalance_mean',\n",
       "       'spread_mean', 'bid_spread_mean', 'ask_spread_mean',\n",
       "       'volume_imbalance_mean', 'total_volume_mean', 'wap_mean',\n",
       "       'trade_log_return_realized_volatility', 'trade_log_return_realized_mad',\n",
       "       'trade_log_return_realized_median_abs_dev',\n",
       "       'trade_seconds_in_bucket_count_unique', 'trade_size_sum',\n",
       "       'trade_order_count_mean', 'trade_dollar_volume_sum', 'stock_id',\n",
       "       'time_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "athletic-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "seeing-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptiveDataset(Dataset):\n",
    "    def __init__(self, X, Y, emb_cols=['stock_id', 'time_id']):\n",
    "        X = X.copy()\n",
    "        self.X1 = X.loc[:,emb_cols].copy().values.astype(np.int64) #categorical columns\n",
    "        self.X2 = X.drop(columns=emb_cols).copy().values.astype(np.float32) #numerical columns\n",
    "        self.y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (np.expand_dims(self.X1[idx], 0), np.expand_dims(self.X2[idx], 0)), np.expand_dims(self.y[idx], 0)\n",
    "    \n",
    "class OptiveDatasetTest(Dataset):\n",
    "    def __init__(self, X, emb_cols=['stock_id', 'time_id']):\n",
    "        X = X.copy()\n",
    "        self.X1 = X.loc[:,emb_cols].copy().values.astype(np.int64) #categorical columns\n",
    "        self.X2 = X.drop(columns=emb_cols).copy().values.astype(np.float32) #numerical columns\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X1)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.X1[idx], self.X2[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "recorded-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.fillna(0)\n",
    "df_test = df_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "available-staff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([4, 1, 1]), torch.Size([4, 1, 20])) torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = OptiveDataset(df_train.drop(['target', 'time_id','row_id'], axis=1), df_train['target'], emb_cols=['stock_id'])\n",
    "train_dl = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "#test the dataset class\n",
    "for (emb, cont), target in train_dl:\n",
    "    print((emb.shape, cont.shape), target.shape)\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "advance-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "def RMSELoss(yhat,y):\n",
    "    return torch.sqrt(torch.mean((yhat-y)**2))\n",
    "\n",
    "def RMSPELoss(y_pred, y_true):\n",
    "    return torch.sqrt(torch.mean( ((y_true - y_pred) / y_true) ** 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "sunset-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptiverModel(nn.Module):\n",
    "    # d_model : number of features\n",
    "    def __init__(self,feature_size=7,num_layers=3,dropout=0, embedding_sizes=16, num_embeddings=max(df_train['stock_id'].astype(np.int8))+1):\n",
    "        super(OptiverModel, self).__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(num_embeddings, embedding_sizes)\n",
    "        self.emb_drop = nn.Dropout(0.25)\n",
    "        self.bn1 = nn.BatchNorm1d(20)\n",
    "        \n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=7, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n",
    "        self.decoder = nn.Linear(feature_size,1)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1    \n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def forward(self, x_cat, x_cont, device):\n",
    "        x1 = self.emb(x_cat)\n",
    "        x1 = torch.flatten(x1, end_dim=1)\n",
    "        x1 = self.emb_drop(x1)\n",
    "        x2 = x_cont.permute(0,2,1)\n",
    "        x2 = self.bn1(x2)\n",
    "#         x2 = x2.permute(0,2,1)\n",
    "        x1 = x1.permute(0,2,1)\n",
    "        x = torch.cat([x1,x2], 1)\n",
    "        x = x.permute(0,2,1)\n",
    "        \n",
    "        mask = self._generate_square_subsequent_mask(len(x)).to(device)\n",
    "        output = self.transformer_encoder(x,mask)\n",
    "        output = self.decoder(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "inner-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_dl, valid_dl, model, loss_fn, opt, sch, epoch, fold, device=device):\n",
    "    # taining loop\n",
    "    model.train()\n",
    "    running_loss_ = 0\n",
    "    \n",
    "    pbar = tqdm(enumerate(train_dl), total=len(train_dl))\n",
    "    for i, ((cats, counts), targets) in pbar:\n",
    "        cats, counts, targets = cats.to(device), counts.to(device), targets.unsqueeze(1).to(device)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        y_pred = model(cats, counts, device)\n",
    "        loss = loss_fn(y_pred.float(), targets.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        running_loss_ += loss.item()\n",
    "        if (i+1) % 100 == 0:\n",
    "            pbar.set_description(f\"running loss:{running_loss_ / (i+1): 0.6f}\")\n",
    "    \n",
    "    sch.step(loss)\n",
    "\n",
    "    epoch_loss = running_loss_ / len(train_dl)\n",
    "    #print(f'==> Epoch {epoch} TRAIN loss: {epoch_loss:.6f}')\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for i, ((cats, counts), targets) in enumerate(valid_dl):\n",
    "        cats, counts, targets = cats.to(device), counts.to(device), targets.unsqueeze(1).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred = model(cats, counts, device)\n",
    "            val_loss = loss_fn(y_pred.float(), targets.float())\n",
    "            \n",
    "        valid_loss += val_loss.item() * targets.shape[0]\n",
    "    sch.step(valid_loss)\n",
    "    \n",
    "    valid_epoch_loss = valid_loss / len(valid_dl)\n",
    "    print(f'==>F{fold}, Epoch {epoch} VALID loss: {valid_epoch_loss:.8f}')\n",
    "    \n",
    "    if valid_epoch_loss < best_loss:\n",
    "        best_loss = valid_epoch_loss\n",
    "        torch.save(model.state_dict(), f'FOLD{fold}_optive_model.pth')\n",
    "    \n",
    "    model.train()\n",
    "    return model, epoch_loss, valid_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "based-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perpare_dataset(train, valid, test=None, batch_size=64, drop_cols=['target', 'time_id', 'row_id'], emb_cols=['stock_id']):\n",
    "    train_dataset = OptiveDataset(train.drop(drop_cols, axis=1), train['target'], emb_cols=emb_cols)\n",
    "    valid_dataset = OptiveDataset(valid.drop(drop_cols, axis=1), valid['target'], emb_cols=emb_cols)    \n",
    "    \n",
    "    train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    valid_dl = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return train_dl, valid_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-keyboard",
   "metadata": {},
   "source": [
    "# Training Loop\n",
    "\n",
    "Conducted remotely on GCP instance - Transformers need more compute!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "integrated-jumping",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.004864: 100%|██████████████████████████████████████████████████████| 6032/6032 [01:13<00:00, 81.57it/s]\n",
      "  0%|                                                                                 | 8/6032 [00:00<01:23, 72.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>F0, Epoch 0 VALID loss: 0.19428741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "running loss: 0.003016:  42%|██████████████████████▍                               | 2508/6032 [00:30<00:42, 83.38it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-6c4d88f75ef5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         model, epoch_loss, valid_epoch_loss = train_epoch(train_dl, valid_dl, \n\u001b[0m\u001b[0;32m     26\u001b[0m                                                                    \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                                                                    sch, epoch, fold_idx, device=device)\n",
      "\u001b[1;32m<ipython-input-30-a52094df0ae3>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(train_dl, valid_dl, model, loss_fn, opt, sch, epoch, fold, device)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-46-89b06628ff91>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x_cat, x_cont, device)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generate_square_subsequent_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[0msrc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m         \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1845\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1847\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_folds = 10\n",
    "epochs = 10\n",
    "\n",
    "kf = model_selection.KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "seed_everything(46)\n",
    "\n",
    "for fold_idx, (dev_index, val_index) in enumerate(kf.split(range(len(train)))):\n",
    "    \n",
    "    if fold_idx > 4:\n",
    "        break #train 5 folds\n",
    "        \n",
    "    train_ = df_train.loc[dev_index,].reset_index(drop=True)\n",
    "    valid_ = df_train.loc[val_index, ].reset_index(drop=True)\n",
    "    \n",
    "    train_dl, valid_dl = perpare_dataset(train_, valid_)\n",
    "    \n",
    "    model = OptiverModel(feature_size=49, dropout=.25, embedding_sizes=29,).to(device)\n",
    "    loss_fn = RMSELoss\n",
    "    \n",
    "    opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "    sch = optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.2, patience=3)\n",
    "    \n",
    "    counter = 0\n",
    "    for epoch in range(epochs):\n",
    "        model, epoch_loss, valid_epoch_loss = train_epoch(train_dl, valid_dl, \n",
    "                                                                   model, loss_fn, opt, \n",
    "                                                                   sch, epoch, fold_idx, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
